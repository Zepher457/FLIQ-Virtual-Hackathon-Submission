{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf404065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pennylane as qml\n",
    "\n",
    "# Pytorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5808d442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros (class 0): 744\n",
      "Ones  (class 1): 855\n",
      "(1599, 11) (1599, 1)\n"
     ]
    }
   ],
   "source": [
    "#Prep Training Data (Breast Cancer Wisconsin)\n",
    "\n",
    "#Load the data file\n",
    "df = pd.read_csv(\"data/winequality-red.csv\", sep = ';', header=0)\n",
    "\n",
    "Y = (df['quality'] >= 6).astype(int).values.reshape(-1,1)\n",
    "X = df.drop(['quality'], axis=1).values\n",
    "\n",
    "\n",
    "mean = X.mean(axis=0)\n",
    "std = X.std(axis=0)\n",
    "X = (X - mean) / std\n",
    "\n",
    "#Convert to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.float32)\n",
    "y = Y_tensor.view(-1).long()     # flatten to shape [N] and cast to int\n",
    "counts = torch.bincount(y)       # bincount over 0,1\n",
    "print(f\"Zeros (class 0): {counts[0].item()}\")\n",
    "print(f\"Ones  (class 1): {counts[1].item()}\")\n",
    "\n",
    "#Manual train/test split (80/20)\n",
    "num_samples = X_tensor.shape[0]\n",
    "indices = torch.randperm(num_samples)\n",
    "\n",
    "split_idx = int(num_samples * 0.8)\n",
    "train_indices = indices[:split_idx]\n",
    "test_indices = indices[split_idx:]\n",
    "X_train = X_tensor[train_indices]\n",
    "Y_train = Y_tensor[train_indices]\n",
    "X_test = X_tensor[test_indices]\n",
    "Y_test = Y_tensor[test_indices]\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677bcdea",
   "metadata": {},
   "source": [
    "The base idea for this model is a quanvolutional neural network that uses multiple quantum kernels for quantum feature extraction. Here I use 3 1D filter kernels of size 3, allowing us to map a 30 feature datapoint to a (9,10) dimension tensor. The output of this is passed into a classical convolutional layer. One can use a quantum convolutional neural network instead, but due to time and resource constraints, I opted for a classical CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eed145c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quanv_dev1 = qml.device('lightning.qubit', wires = 3)\n",
    "@qml.qnode(quanv_dev1, interface='torch', diff_method = 'best')\n",
    "def quanv_circ1(input_vals, params):\n",
    "    qml.IQPEmbedding(input_vals, list(range(len(input_vals))))\n",
    "    for j in range(3):\n",
    "        qml.U3(params[3*j], \n",
    "                params[3*j + 1], \n",
    "                params[3*j + 2],\n",
    "                wires = j)\n",
    "    qml.CNOT(wires = [1,2])\n",
    "    qml.IsingXX(params[3*3], wires = [0,1])\n",
    "    qml.IsingYY(params[3*3 + 1], wires = [0,1])\n",
    "    qml.IsingZZ(params[3*3 + 2], wires = [0,1])\n",
    "    qml.CNOT(wires = [1,2])\n",
    "    for j in range(3):\n",
    "        qml.U3(params[3*j + 12], \n",
    "                params[3*j + 1 + 12], \n",
    "                params[3*j + 2 + 12],\n",
    "                wires = j)\n",
    "    \n",
    "    return [qml.expval(qml.PauliZ(i)) for i in [0,1,2]]\n",
    "\n",
    "qsvt_dev = qml.device('default.mixed', wires = 4)\n",
    "@qml.qnode(qsvt_dev, interface='torch', diff_method = 'best')\n",
    "def qsvt_circ(input_vals):\n",
    "    A = torch.diag(input_vals)\n",
    "    angles = [0,0]\n",
    "    qml.qsvt(A, angles, wires = list(range(4)))\n",
    "    return qml.probs(wires = list(range(4)))\n",
    "\n",
    "def quanv(data, window_size, params, num_qubits):\n",
    "    num_qubits = 3\n",
    "    dim = data.size(1)\n",
    "    out_cols = dim - window_size + 1\n",
    "    out = torch.zeros((num_qubits, out_cols))\n",
    "    for idx, start in enumerate(range(0, out_cols)):\n",
    "        seg1 = data[0, start:start+window_size]\n",
    "        q1 = quanv_circ1(seg1, params[:21])\n",
    "        for i in range(num_qubits):\n",
    "            out[i, idx] = q1[i]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e18c30",
   "metadata": {},
   "source": [
    "Here, you can see the architecture of the model, including the classical layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5be646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.q_params = nn.ParameterList(\n",
    "            [\n",
    "                nn.Parameter(torch.randn((46))*np.pi, requires_grad=True)\n",
    "            ]\n",
    "        )\n",
    "        self.classical = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(in_channels = 16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(2*32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        quanv_output = None\n",
    "        for q_param in self.q_params:\n",
    "            quanv_output = quanv(x, 3, q_param, 3).view(1,3,9)\n",
    "        convolution_output = self.classical(quanv_output).view(1, 32*2)\n",
    "        output = self.output(convolution_output)\n",
    "        return output\n",
    "    # quanv_output = None\n",
    "    #     qsvt_output = torch.zeros((3, 2**4))\n",
    "    #     for q_param in self.q_params:\n",
    "    #         quanv_output = quanv(x, 4, q_param, 3).view(3,8)\n",
    "    #     for i, q_output in enumerate(quanv_output):\n",
    "    #         qsvt_output[i, :] = qsvt_circ(q_output)\n",
    "    #     qsvt_output = qsvt_output.view(1, 3, 16)\n",
    "    #     convolution_output = self.classical(qsvt_output).view(1, 128)\n",
    "    #     output = self.output(convolution_output)\n",
    "    #     return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf4fd4f",
   "metadata": {},
   "source": [
    "Methods to evaluate robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "71c812a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def fgsm_attack(model, x, y, epsilon, device):\n",
    "    x_adv = x.clone().detach().to(device).requires_grad_(True)\n",
    "    out = model(x_adv)\n",
    "\n",
    "    if out.dim()==2 and out.size(1)==1:\n",
    "        out = out.view(-1)\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(out.unsqueeze(0), y.float().to(device))\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
    "    return x_adv.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a053a6",
   "metadata": {},
   "source": [
    "Training loop. I used a regularization loss term since I was finding that this model fits easily to the training dataset. Compared to a simple classical CNN classifier, unfortunately we acquire lower test accuracy, F-1 score, precision, and recall. Nonetheless, I thought this model performed quite well on this particular dataset, where it appeared difficult to acquire any comparable performance to a classical classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c0e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Fold 1/5\n",
      "  pos/neg = 550/473 → pos_weight = 0.86\n",
      "    Epoch 01 — loss 0.6275\n",
      "    Epoch 02 — loss 0.6044\n",
      "    Epoch 03 — loss 0.5669\n",
      "    Epoch 04 — loss 0.5432\n",
      "    Epoch 05 — loss 0.5264\n",
      "    Epoch 06 — loss 0.4985\n",
      "    Epoch 07 — loss 0.4862\n",
      "    Epoch 08 — loss 0.4614\n",
      "    Epoch 09 — loss 0.4383\n",
      "    Epoch 10 — loss 0.4189\n",
      "    Epoch 11 — loss 0.4030\n",
      "    Epoch 12 — loss 0.3748\n",
      "    Epoch 13 — loss 0.3500\n",
      "    Epoch 14 — loss 0.3324\n",
      "    Epoch 15 — loss 0.3032\n",
      "    Epoch 16 — loss 0.2869\n",
      "    Epoch 17 — loss 0.2785\n",
      "    Epoch 18 — loss 0.2433\n",
      "    Epoch 19 — loss 0.2300\n",
      "    Epoch 20 — loss 0.2134\n",
      "    Epoch 21 — loss 0.1961\n",
      "    Epoch 22 — loss 0.1811\n",
      "    Epoch 23 — loss 0.1644\n",
      "    Epoch 24 — loss 0.1577\n",
      "    Epoch 25 — loss 0.1442\n",
      "    Epoch 26 — loss 0.1212\n",
      "    Epoch 27 — loss 0.1158\n",
      "    Epoch 28 — loss 0.1108\n",
      "    Epoch 29 — loss 0.0944\n",
      "    Epoch 30 — loss 0.0863\n",
      "\n",
      "→ Fold 2/5\n",
      "  pos/neg = 550/473 → pos_weight = 0.86\n",
      "    Epoch 01 — loss 0.6351\n",
      "    Epoch 02 — loss 0.6017\n",
      "    Epoch 03 — loss 0.5745\n",
      "    Epoch 04 — loss 0.5493\n",
      "    Epoch 05 — loss 0.5174\n",
      "    Epoch 06 — loss 0.4944\n",
      "    Epoch 07 — loss 0.4724\n",
      "    Epoch 08 — loss 0.4531\n",
      "    Epoch 09 — loss 0.4466\n",
      "    Epoch 10 — loss 0.4179\n",
      "    Epoch 11 — loss 0.4094\n",
      "    Epoch 12 — loss 0.3876\n",
      "    Epoch 13 — loss 0.3688\n",
      "    Epoch 14 — loss 0.3565\n",
      "    Epoch 15 — loss 0.3288\n",
      "    Epoch 16 — loss 0.3182\n",
      "    Epoch 17 — loss 0.3002\n",
      "    Epoch 18 — loss 0.2920\n",
      "    Epoch 19 — loss 0.2659\n",
      "    Epoch 20 — loss 0.2490\n",
      "    Epoch 21 — loss 0.2430\n",
      "    Epoch 22 — loss 0.2191\n",
      "    Epoch 23 — loss 0.2068\n",
      "    Epoch 24 — loss 0.1976\n",
      "    Epoch 25 — loss 0.1758\n",
      "    Epoch 26 — loss 0.1635\n",
      "    Epoch 27 — loss 0.1652\n",
      "    Epoch 28 — loss 0.1497\n",
      "    Epoch 29 — loss 0.1333\n",
      "    Epoch 30 — loss 0.1206\n",
      "\n",
      "→ Fold 3/5\n",
      "  pos/neg = 549/474 → pos_weight = 0.86\n",
      "    Epoch 01 — loss 0.6311\n",
      "    Epoch 02 — loss 0.5953\n",
      "    Epoch 03 — loss 0.5616\n",
      "    Epoch 04 — loss 0.5304\n",
      "    Epoch 05 — loss 0.5077\n",
      "    Epoch 06 — loss 0.4888\n",
      "    Epoch 07 — loss 0.4669\n",
      "    Epoch 08 — loss 0.4463\n",
      "    Epoch 09 — loss 0.4387\n",
      "    Epoch 10 — loss 0.4210\n",
      "    Epoch 11 — loss 0.4019\n",
      "    Epoch 12 — loss 0.3856\n",
      "    Epoch 13 — loss 0.3653\n",
      "    Epoch 14 — loss 0.3581\n",
      "    Epoch 15 — loss 0.3304\n",
      "    Epoch 16 — loss 0.3148\n",
      "    Epoch 17 — loss 0.2925\n",
      "    Epoch 18 — loss 0.2826\n",
      "    Epoch 19 — loss 0.2733\n",
      "    Epoch 20 — loss 0.2480\n",
      "    Epoch 21 — loss 0.2228\n",
      "    Epoch 22 — loss 0.2066\n",
      "    Epoch 23 — loss 0.1927\n",
      "    Epoch 24 — loss 0.1703\n",
      "    Epoch 25 — loss 0.1603\n",
      "    Epoch 26 — loss 0.1471\n",
      "    Epoch 27 — loss 0.1274\n",
      "    Epoch 28 — loss 0.1170\n",
      "    Epoch 29 — loss 0.1129\n",
      "    Epoch 30 — loss 0.1001\n",
      "\n",
      "→ Fold 4/5\n",
      "  pos/neg = 549/474 → pos_weight = 0.86\n",
      "    Epoch 01 — loss 0.6340\n",
      "    Epoch 02 — loss 0.5967\n",
      "    Epoch 03 — loss 0.5610\n",
      "    Epoch 04 — loss 0.5365\n",
      "    Epoch 05 — loss 0.5115\n",
      "    Epoch 06 — loss 0.4933\n",
      "    Epoch 07 — loss 0.4793\n",
      "    Epoch 08 — loss 0.4601\n",
      "    Epoch 09 — loss 0.4451\n",
      "    Epoch 10 — loss 0.4244\n",
      "    Epoch 11 — loss 0.4079\n",
      "    Epoch 12 — loss 0.3807\n",
      "    Epoch 13 — loss 0.3595\n",
      "    Epoch 14 — loss 0.3370\n",
      "    Epoch 15 — loss 0.3217\n",
      "    Epoch 16 — loss 0.3003\n",
      "    Epoch 17 — loss 0.2776\n",
      "    Epoch 18 — loss 0.2557\n",
      "    Epoch 19 — loss 0.2357\n",
      "    Epoch 20 — loss 0.2284\n",
      "    Epoch 21 — loss 0.2012\n",
      "    Epoch 22 — loss 0.1943\n",
      "    Epoch 23 — loss 0.1687\n",
      "    Epoch 24 — loss 0.1646\n",
      "    Epoch 25 — loss 0.1515\n",
      "    Epoch 26 — loss 0.1379\n",
      "    Epoch 27 — loss 0.1273\n",
      "    Epoch 28 — loss 0.1126\n",
      "    Epoch 29 — loss 0.1050\n",
      "    Epoch 30 — loss 0.0935\n",
      "\n",
      "→ Fold 5/5\n",
      "  pos/neg = 550/474 → pos_weight = 0.86\n",
      "    Epoch 01 — loss 0.6313\n",
      "    Epoch 02 — loss 0.5842\n",
      "    Epoch 03 — loss 0.5483\n",
      "    Epoch 04 — loss 0.5182\n",
      "    Epoch 05 — loss 0.5009\n",
      "    Epoch 06 — loss 0.4778\n",
      "    Epoch 07 — loss 0.4560\n",
      "    Epoch 08 — loss 0.4391\n",
      "    Epoch 09 — loss 0.4196\n",
      "    Epoch 10 — loss 0.3974\n",
      "    Epoch 11 — loss 0.3810\n",
      "    Epoch 12 — loss 0.3594\n",
      "    Epoch 13 — loss 0.3478\n",
      "    Epoch 14 — loss 0.3254\n",
      "    Epoch 15 — loss 0.2991\n",
      "    Epoch 16 — loss 0.2832\n",
      "    Epoch 17 — loss 0.2632\n",
      "    Epoch 18 — loss 0.2478\n",
      "    Epoch 19 — loss 0.2245\n",
      "    Epoch 20 — loss 0.2089\n",
      "    Epoch 21 — loss 0.1951\n",
      "    Epoch 22 — loss 0.1822\n",
      "    Epoch 23 — loss 0.1642\n",
      "    Epoch 24 — loss 0.1557\n",
      "    Epoch 25 — loss 0.1440\n",
      "    Epoch 26 — loss 0.1328\n",
      "    Epoch 27 — loss 0.1251\n",
      "    Epoch 28 — loss 0.1113\n",
      "    Epoch 29 — loss 0.1012\n",
      "    Epoch 30 — loss 0.0948\n",
      "Ensemble Test Accuracy:   0.68125\n",
      "Ensemble Test Precision:  0.7171052631578947\n",
      "Ensemble Test Recall:     0.6488095238095238\n",
      "Ensemble Test F1-score:   0.68125\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# — configs — \n",
    "device       = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "k_folds      = 5\n",
    "n_epochs     = 30\n",
    "batch_size   = 1\n",
    "lr           = 0.0002\n",
    "betas        = (0.5, 0.999)\n",
    "weight_decay = 0.005\n",
    "\n",
    "# Your existing train/test split:\n",
    "X_tr = X_train.cpu()          # we'll .to(device) inside loop\n",
    "Y_tr = Y_train.view(-1).cpu().long()\n",
    "X_te = X_test.to(device)\n",
    "Y_te = Y_test.view(-1).to(device).long()\n",
    "\n",
    "ensemble_models = []\n",
    "\n",
    "# Stratify only on the training set—ignore the val indices\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "for fold, (train_idx, _) in enumerate(skf.split(X_tr, Y_tr), 1):\n",
    "    print(f\"\\n→ Fold {fold}/{k_folds}\")\n",
    "\n",
    "    # Build fold‐specific loader\n",
    "    X_fold = X_tr[train_idx].to(device)\n",
    "    Y_fold = Y_tr[train_idx].to(device)\n",
    "    train_loader = DataLoader(\n",
    "        TensorDataset(X_fold, Y_fold),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    # Compute pos_weight = (#neg / #pos) on this fold\n",
    "    n_pos = int((Y_fold==1).sum().item())\n",
    "    n_neg = int((Y_fold==0).sum().item())\n",
    "    pos_weight = n_neg / n_pos\n",
    "    print(f\"  pos/neg = {n_pos}/{n_neg} → pos_weight = {pos_weight:.2f}\")\n",
    "\n",
    "    # Instantiate & train a fresh model\n",
    "    model_f = HybridModel().to(device)\n",
    "    optimizer_f = torch.optim.Adam(\n",
    "        model_f.parameters(),\n",
    "        lr=lr, betas=betas, weight_decay=weight_decay\n",
    "    )\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        model_f.train()\n",
    "        running_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer_f.zero_grad()\n",
    "            pred = model_f(xb).view(-1)\n",
    "            weights = torch.where(\n",
    "                yb==1,\n",
    "                torch.tensor(pos_weight, device=device),\n",
    "                torch.tensor(1.0,        device=device)\n",
    "            )\n",
    "            loss = F.binary_cross_entropy(pred, yb.float(), weight=weights)\n",
    "            loss.backward()\n",
    "            optimizer_f.step()\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "        print(f\"    Epoch {epoch:02d} — loss {running_loss/len(train_loader.dataset):.4f}\")\n",
    "\n",
    "    model_f.eval()\n",
    "    ensemble_models.append(model_f)\n",
    "\n",
    "# — Ensemble on the hold-out test set —\n",
    "all_probs = []\n",
    "with torch.no_grad():\n",
    "    for m in ensemble_models:\n",
    "        probs = []\n",
    "        for x in X_te:\n",
    "            p = m(x.unsqueeze(0)).view(-1)[0].item()\n",
    "            probs.append(p)\n",
    "        all_probs.append(probs)\n",
    "\n",
    "avg_probs  = np.mean(np.vstack(all_probs), axis=0)\n",
    "y_pred_ens = (avg_probs >= 0.5).astype(int)\n",
    "y_true_te  = Y_te.cpu().numpy()\n",
    "\n",
    "print(\"Ensemble Test Accuracy:  \", accuracy_score(y_true_te, y_pred_ens))\n",
    "print(\"Ensemble Test Precision: \", precision_score(y_true_te, y_pred_ens))\n",
    "print(\"Ensemble Test Recall:    \", recall_score(y_true_te, y_pred_ens))\n",
    "print(\"Ensemble Test F1-score:  \", f1_score(y_true_te, y_pred_ens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7aa41b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Test Accuracy:   68.125\n",
      "Ensemble Test Precision:  0.7171052631578947\n",
      "Ensemble Test Recall:     0.6488095238095238\n",
      "Ensemble Test F1-score:   0.68125\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensemble Test Accuracy:  \", accuracy_score(y_true_te, y_pred_ens)*100)\n",
    "print(\"Ensemble Test Precision: \", precision_score(y_true_te, y_pred_ens))\n",
    "print(\"Ensemble Test Recall:    \", recall_score(y_true_te, y_pred_ens))\n",
    "print(\"Ensemble Test F1-score:  \", f1_score(y_true_te, y_pred_ens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "305af71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy vs ε: {0.0: 0.68125, 0.01: 0.634375, 0.05: 0.4125, 0.1: 0.23125, 0.2: 0.109375}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_ensemble_robustness(ensemble_models, device, X_test, Y_test, epsilons):\n",
    "    \"\"\"\n",
    "    Evaluate ensemble accuracy under FGSM attack for various epsilons.\n",
    "    For each epsilon:\n",
    "      - For each model in the ensemble:\n",
    "          • Generate adversarial examples on X_test (per-sample FGSM).\n",
    "          • Collect model probabilities on those adversarial inputs.\n",
    "      - Average probabilities across models.\n",
    "      - Threshold at 0.5 and compute accuracy.\n",
    "    Returns a dict mapping epsilon -> ensemble accuracy.\n",
    "    \"\"\"\n",
    "    ensemble_robustness = {}\n",
    "\n",
    "    for eps in epsilons:\n",
    "        # Collect per-model probability lists\n",
    "        per_model_probs = []\n",
    "\n",
    "        for model in ensemble_models:\n",
    "            model.eval()\n",
    "            probs = []\n",
    "            for i in range(X_test.size(0)):\n",
    "                x = X_test[i].unsqueeze(0).to(device)\n",
    "                y = Y_test[i].unsqueeze(0).long().to(device)\n",
    "                # generate adversarial or keep clean\n",
    "                if eps > 0.0:\n",
    "                    x_adv = fgsm_attack(model, x, y, eps, device)\n",
    "                else:\n",
    "                    x_adv = x\n",
    "                with torch.no_grad():\n",
    "                    p = model(x_adv).view(-1)[0].item()  # assumes sigmoid final\n",
    "                probs.append(p)\n",
    "            per_model_probs.append(probs)\n",
    "\n",
    "        # average probabilities across models: shape = [n_test]\n",
    "        avg_probs = np.mean(np.array(per_model_probs), axis=0)\n",
    "        y_pred = (avg_probs >= 0.5).astype(int)\n",
    "        y_true = Y_test.view(-1).cpu().numpy().astype(int)\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        ensemble_robustness[eps] = acc\n",
    "\n",
    "    return ensemble_robustness\n",
    "\n",
    "# — USAGE —\n",
    "epsilons = [0.0, 0.01, 0.05, 0.1, 0.2]\n",
    "ensemble_robustness = evaluate_ensemble_robustness(\n",
    "    ensemble_models, device, X_test, Y_test, epsilons\n",
    ")\n",
    "print(\"Ensemble Accuracy vs ε:\", ensemble_robustness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7da7e284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19915"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "num_params = 0\n",
    "for expert in ensemble_models:\n",
    "    num_params += count_parameters(expert)\n",
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edda763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble params\n",
    "# ensemble_state = {\n",
    "#     f'fold_{i}': m.state_dict()\n",
    "#     for i, m in enumerate(ensemble_models, start=1)\n",
    "# }\n",
    "# torch.save(ensemble_state, 'wine_ensemble_models.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f559597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in ensemble\n",
    "checkpoint = torch.load('wine_ensemble_models.pth', map_location=device)\n",
    "loaded_models = []\n",
    "for key, state in checkpoint.items():\n",
    "    m = HybridModel().to(device)\n",
    "    m.load_state_dict(state)\n",
    "    m.eval()\n",
    "    loaded_models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0292d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
